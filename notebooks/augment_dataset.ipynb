{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Padd import ObjectAdder\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from PATHS.PaddGaragePaths import IMAGES_DATASET_PATH, GENRATED_OBJECTS\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entityseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11580"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_directory = IMAGES_DATASET_PATH\n",
    "\n",
    "scene_files = sorted(os.listdir(scene_directory))\n",
    "generated_objects_directory = GENRATED_OBJECTS\n",
    "len(scene_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineImagesHorizontally(*images):\n",
    "    if not images:\n",
    "        raise ValueError(\"No images provided\")\n",
    "\n",
    "    total_width = sum(img.width for img in images)\n",
    "    max_height = max(img.height for img in images)\n",
    "\n",
    "    combined_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        combined_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self, root_dir: str):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_names = self._get_class_names(root_dir)\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _get_class_names(self, root_dir: str) -> List[str]:\n",
    "        class_names = []\n",
    "        for entry in os.listdir(root_dir):\n",
    "            entry_path = os.path.join(root_dir, entry)\n",
    "            if os.path.isdir(entry_path):\n",
    "                class_names.append(entry)\n",
    "        return class_names\n",
    "\n",
    "    def _load_data(self) -> Dict[str, Dict[str, Any]]:\n",
    "        data = {}\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            prompts_path = os.path.join(class_dir, 'prompts.json')\n",
    "            with open(prompts_path, 'r') as f:\n",
    "                prompts = json.load(f)\n",
    "\n",
    "            images_dir = os.path.join(class_dir, 'images')\n",
    "            data[class_name] = {\n",
    "                'prompts': prompts,\n",
    "                'images_dir': images_dir\n",
    "            }\n",
    "        return data\n",
    "\n",
    "    def get_batch(self, n: int, seed: int = None) -> Tuple[List[Image.Image], List[Image.Image], List[str]]:\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        images = []\n",
    "        masks = []\n",
    "        prompts = []\n",
    "\n",
    "        all_data = []\n",
    "        for class_name in self.class_names:\n",
    "            class_data = self.data[class_name]\n",
    "            for prompt_key in class_data['prompts'].keys():\n",
    "                all_data.append((class_name, prompt_key, class_data['prompts'][prompt_key]))\n",
    "\n",
    "        random.shuffle(all_data)\n",
    "\n",
    "        for _ in range(n):\n",
    "            if not all_data:\n",
    "                break\n",
    "\n",
    "            class_name, prompt_key, prompt = all_data.pop()\n",
    "            class_data = self.data[class_name]\n",
    "            image_dir = os.path.join(class_data['images_dir'], prompt_key)\n",
    "\n",
    "            image_path = os.path.join(image_dir, 'object_raw_image.jpg')\n",
    "            mask_path = os.path.join(image_dir, 'mask.jpg')\n",
    "\n",
    "            image = Image.open(image_path)\n",
    "            mask = Image.open(mask_path)\n",
    "\n",
    "            images.append(image)\n",
    "            masks.append(mask)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        return images, masks, prompts\n",
    "\n",
    "    def get_item_by_class_and_index(self, class_name: str, index: int) -> Tuple[Image.Image, Image.Image, str]:\n",
    "        class_data = self.data[class_name]\n",
    "        prompt_key = list(class_data['prompts'].keys())[index]\n",
    "        prompt = class_data['prompts'][prompt_key]\n",
    "        image_dir = os.path.join(class_data['images_dir'], prompt_key)\n",
    "\n",
    "        image_path = os.path.join(image_dir, 'object_raw_image.jpg')\n",
    "        mask_path = os.path.join(image_dir, 'mask.jpg')\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        return image, mask, prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(generated_objects_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectAdder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 800\n",
    "for file in tqdm(scene_files[num:1000]):\n",
    "    scene = Image.open(os.path.join(scene_directory, file))\n",
    "    batch = dataset.get_batch(n=5, seed=num)\n",
    "    try:\n",
    "        new_images, controlnet_images = model(scene, batch[0], batch[1], batch[2], seed=num)\n",
    "        if new_images == []:\n",
    "            continue\n",
    "        combine_image = CombineImagesHorizontally(*new_images, *controlnet_images)\n",
    "        new_image = new_images[-1]\n",
    "        new_image.save(\"augmentations/images/\" + file)\n",
    "        combine_image.save(\"augmentations/combine_images/\" + file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error, start new iteration\")\n",
    "        continue\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"augmentations/images/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
